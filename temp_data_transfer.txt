(.venv) C:\Users\jakep\Desktop\reusable_profiles>python src\experiments\k_sweep_volatile.py
======================================================================
K-SWEEP OPTIMIZATION: VARIABLE VOLATILITY TASK
======================================================================
Task: Regime-dependent TRADE-OFFS between exploration and exploitation

  STABLE regime (exploitation-favored):
    - Hint accuracy: 55% (barely useful)
    - Reward probability: 90% (easy to learn from feedback)
    - Reversals: Rare (every 60 trials)
    → Optimal: Ignore hints, exploit learned preferences

  VOLATILE regime (exploration-favored):
    - Hint accuracy: 95% (very reliable)
    - Reward probability: 65% (noisy feedback)
    - Reversals: Frequent (every 8 trials)
    → Optimal: Use hints to track rapid changes


======================================================================
Optimizing K=1 profiles for VARIABLE VOLATILITY task
======================================================================
Total parameters: 6
Bounds: 6
Running optimization with 3 runs per evaluation...

Using 19 parallel workers (leaving 1 core free)

differential_evolution step 1: f(x)= 0.0006890427049954497
differential_evolution step 2: f(x)= 0.0006890427049954497
differential_evolution step 3: f(x)= 0.0006890427049954497

Optimization complete!
Best objective value: 0.0007
  (Note: objective = -total_rewards + 0.01*(-mean_ll), lower is better)
  This prioritizes: 1) total rewards earned, 2) reasonable LL

Evaluating optimized K=1 model on variable volatility...
Evaluating K=1: 100%|███████████████████████████████████████████████████| 20/20 [00:30<00:00,  1.51s/it] 

K=1 Final Results:
  Mean LL: -0.07
  Total Rewards: 316.2 / 400 trials
  Reward Rate: 0.791
  Choice Ratio: 1.000 (fraction of trials with left/right)
  Stable Hint Usage: 0.000 ± 0.000
  Volatile Hint Usage: 0.000 ± 0.000
  Stable Reward Rate: 0.795 ± 0.034
  Volatile Reward Rate: 0.784 ± 0.005
  Optimized profiles:
    Profile 0: γ=7.95, φ=-4.68/5.36, ξ_hint=0.24, ξ_left=0.29, ξ_right=0.60
  Z matrix:
[[1.]
 [1.]]

======================================================================
Optimizing K=2 profiles for VARIABLE VOLATILITY task
======================================================================
Total parameters: 14
Bounds: 14
Running optimization with 3 runs per evaluation...

Using 19 parallel workers (leaving 1 core free)

differential_evolution step 1: f(x)= 0.0006350455028917062
differential_evolution step 2: f(x)= 0.0006350455028917062
differential_evolution step 3: f(x)= 0.00038493588436126986

Optimization complete!
Best objective value: 0.0004
  (Note: objective = -total_rewards + 0.01*(-mean_ll), lower is better)
  This prioritizes: 1) total rewards earned, 2) reasonable LL

Evaluating optimized K=2 model on variable volatility...
Evaluating K=2: 100%|███████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.65s/it] 

K=2 Final Results:
  Mean LL: -0.04
  Total Rewards: 317.4 / 400 trials
  Reward Rate: 0.793
  Choice Ratio: 1.000 (fraction of trials with left/right)
  Stable Hint Usage: 0.000 ± 0.000
  Volatile Hint Usage: 0.000 ± 0.000
  Stable Reward Rate: 0.799 ± 0.034
  Volatile Reward Rate: 0.785 ± 0.004
  Optimized profiles:
    Profile 0: γ=7.28, φ=-3.90/4.16, ξ_hint=-0.12, ξ_left=-1.27, ξ_right=1.48
    Profile 1: γ=7.74, φ=-11.37/4.30, ξ_hint=-1.03, ξ_left=1.03, ξ_right=-1.48
  Z matrix:
[[0.06721655 0.93278345]
 [0.90902745 0.09097255]]

======================================================================
Optimizing K=3 profiles for VARIABLE VOLATILITY task
======================================================================
Total parameters: 22
Bounds: 22
Running optimization with 3 runs per evaluation...

Using 19 parallel workers (leaving 1 core free)

