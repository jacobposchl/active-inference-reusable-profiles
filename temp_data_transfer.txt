(.venv) C:\Users\jakep\Desktop\reusable_profiles>python src/experiments/k_sweep_volatile.py
======================================================================
K-SWEEP OPTIMIZATION: VARIABLE VOLATILITY TASK
======================================================================
Task: Regime-dependent TRADE-OFFS between exploration and exploitation

  STABLE regime (exploitation-favored):
    - Hint accuracy: 55% (barely useful)
    - Reward probability: 85% (reliable feedback signal)
    - Reversals: Rare (every 60 trials)
    → Optimal: Ignore hints, exploit learned preferences

  VOLATILE regime (exploration-favored):
    - Hint accuracy: 95% (very reliable)
    - Reward probability: 50% (RANDOM - uninformative feedback)
    - Reversals: Frequent (every 8 trials)
    → Optimal: Use hints to track rapid changes


======================================================================
Optimizing K=1 profiles for VARIABLE VOLATILITY task
======================================================================
Total parameters: 6
Bounds: 6
Running optimization with 3 runs per evaluation...

Using 19 parallel workers (leaving 1 core free)

differential_evolution step 1: f(x)= -241.99538655791298
differential_evolution step 2: f(x)= -241.99538655791298
differential_evolution step 3: f(x)= -241.99538655791298

Optimization complete!
Best objective value: -241.9954
  (Note: objective = -total_rewards + 0.01*(-mean_ll), lower is better)
  This prioritizes: 1) total rewards earned, 2) reasonable LL

Evaluating optimized K=1 model on variable volatility...
Evaluating K=1: 100%|███████████████████████████████████████████████████| 20/20 [00:30<00:00,  1.51s/it] 

K=1 Final Results:
  Mean LL: -0.47
  Total Rewards: 274.0 / 400 trials
  Reward Rate: 0.685
  Choice Ratio: 0.995 (fraction of trials with left/right)
  Stable Hint Usage: 0.001 ± 0.002
  Volatile Hint Usage: 0.010 ± 0.007
  Stable Reward Rate: 0.813 ± 0.022
  Volatile Reward Rate: 0.493 ± 0.047
  Optimized profiles:
    Profile 0: γ=5.86, φ=-10.85/3.38, ξ_hint=2.85, ξ_left=-0.67, ξ_right=-0.04
  Z matrix:
[[1.]
 [1.]]

======================================================================
Optimizing K=2 profiles for VARIABLE VOLATILITY task
======================================================================
Total parameters: 14
Bounds: 14
Running optimization with 3 runs per evaluation...

Using 19 parallel workers (leaving 1 core free)

differential_evolution step 1: f(x)= -249.99581604754525
differential_evolution step 2: f(x)= -249.99581604754525
differential_evolution step 3: f(x)= -255.99354795595485

Optimization complete!
Best objective value: -255.9935
  (Note: objective = -total_rewards + 0.01*(-mean_ll), lower is better)
  This prioritizes: 1) total rewards earned, 2) reasonable LL

Evaluating optimized K=2 model on variable volatility...
Evaluating K=2: 100%|███████████████████████████████████████████████████| 20/20 [00:30<00:00,  1.52s/it] 

K=2 Final Results:
  Mean LL: -0.65
  Total Rewards: 272.4 / 400 trials
  Reward Rate: 0.681
  Choice Ratio: 0.998 (fraction of trials with left/right)
  Stable Hint Usage: 0.002 ± 0.002
  Volatile Hint Usage: 0.003 ± 0.003
  Stable Reward Rate: 0.809 ± 0.024
  Volatile Reward Rate: 0.489 ± 0.038
  Optimized profiles:
    Profile 0: γ=1.54, φ=-3.02/4.93, ξ_hint=1.17, ξ_left=-0.38, ξ_right=-0.58
    Profile 1: γ=7.63, φ=-5.79/0.23, ξ_hint=1.22, ξ_left=-1.13, ξ_right=-0.28
  Z matrix:
[[0.80903855 0.19096145]
 [0.55167194 0.44832806]]

======================================================================
Optimizing K=3 profiles for VARIABLE VOLATILITY task
======================================================================
Total parameters: 22
Bounds: 22
Running optimization with 3 runs per evaluation...

Using 19 parallel workers (leaving 1 core free)

